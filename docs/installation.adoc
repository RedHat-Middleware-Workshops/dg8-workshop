=== Deployment: What's an Operator and how does it help us?
:experimental:

An Operator is a method of packaging, deploying, and managing a Kubernetes-native application. A Kubernetes-native application is an application that is both deployed on Kubernetes and managed using the Kubernetes APIs and tooling. An Operator is essentially a custom controller and encapsulates operational knowledge.

A controller is a core concept in Kubernetes and is implemented as a software loop that runs continuously on Kubernetes comparing, and if necessary, reconciling the expressed desired state and the current state of an object. Objects are well known resources like `Pods`, `Services`, `ConfigMaps`, or `PersistentVolumes`. Operators apply this model at the level of entire applications and are, in effect, application-specific controllers.

The Operator is a piece of software running in a `Pod` on the cluster, interacting with the Kubernetes API server. It introduces new object types through Custom Resource Definitions, an extension mechanism in Kubernetes. These custom objects are the primary interface for a user; consistent with the resource-based interaction model on the Kubernetes cluster.

An Operator watches for these custom resource types and is notified about their presence or modification. When the Operator receives this notification it will start running a loop to ensure that all the required connections for the application service represented by these objects are actually available and configured in the way the user expressed in the objectâ€™s specification.

The Operator Lifecycle Manager (OLM) is the backplane that facilitates management of operators on a Kubernetes cluster. Operators that provide popular applications as a service are going to be long-lived workloads with, potentially, lots of permissions on the cluster.

With OLM, administrators can control which Operators are available in what namespaces and who can interact with running Operators. The permissions of an Operator are accurately configured automatically to follow a least-privilege approach. OLM manages the overall lifecycle of Operators and their resources, by doing things like resolving dependencies on other Operators, triggering updates to both an Operator and the application it manages, or granting a team access to an Operator for their slice of the cluster.

Red Hat Data Grid 8.0 comes with an Operator. The administrators of the cluster you are working with today have already installed the Data Grid Operator. What we need to do as a user is define a Custom Resource as to how and what configuration we want for our Red Hat Data Grid instances. 

=== Installing
If you have not already logged into OpenShift from the CodeReady Workspaces terminal, please do that now.Click on the `Login to Openshift` menu in the right menu called 'My Workspace'. When prompted, your *Username* is `{{ USER_ID }}` and your *Password* is `{{ OPENSHIFT_USER_PASSWORD }}`.

Open a new browser to the link:{{ CONSOLE_URL }}[OpenShift web console^]

image::openshift_login.png[openshift_login, 700]

Login using:

* Username: `{{ USER_ID }}`
* Password: `{{ OPENSHIFT_USER_PASSWORD }}!`

Once Logged in, goto your project `{{ USER_ID }}-cache`
Click the link Installed Operator on the left, as shown in the picture below.

image::dg_operatorinstalled.png[openshift_login, 700]

Notice that the DataGrid operator is already installed in your namespace. 

image::dg_operatoroverview.png[openshift_login, 700]

You can see there are no clusters installed in our namespace. Let's go ahead and do that. 

Click on `Create Infinispan` and replace the follwing YAML with the default sample: 

[source, yaml, role="copypaste"]
----
apiVersion: infinispan.org/v1
kind: Infinispan <1>
metadata:
  name: datagrid-service <2>
  namespace: {{ USER_ID }}-cache
spec:
  replicas: 2 <3>
  expose:
    type: LoadBalancer <4>
----

<1> Tell Kubernetes/Openshift that the Custom resource type is Infinispan
<2> Specify the name of our cluster as datagrid-service
<3> Specify the replicas we want for our service
<4> Finally we want this instance to be accessible from outside (i.e. OpenShift Web Console)

Also notice that we are calling our service `datagrid-service`, we will use this name in the following labs to access our cluster.

Click *Create* at the bottom.

You can watch the Red Hat Data Grid Operator creating the instances by running the following command:

[source, shell, role="copypaste"]
----
oc get pods
----

Above command should render a similar output as below:

[source, shell]
----
[jboss@workspacel7b3gw19zpoclvcu dg8-operator]$ oc get pods
NAME                                   READY   STATUS    RESTARTS   AGE
datagrid-service-0                     1/1     Running   0          2m59s
datagrid-service-1                     1/1     Running   0          2m14s
infinispan-operator-544ff55c59-4s7wl   1/1     Running   1          2d10h
----

[source, shell, role="copypaste"]
----
oc get services
----

The above command should render a similar output as shown in the example below. Showing all the services:

[source, shell]
----
NAME                        TYPE           CLUSTER-IP       EXTERNAL-IP                                                                    PORT(S)           AGE
datagrid-service            ClusterIP      172.30.115.185   <none>                                                                         11222/TCP         5m55s
datagrid-service-external   LoadBalancer   172.30.90.75     abd9b45a50a174648af684c05cba0bd9-1926931502.ap-southeast-1.elb.amazonaws.com   11222:32206/TCP   5m55s
datagrid-service-ping       ClusterIP      None             <none>                                                                         8888/TCP          5m55s
----

You can see that there are three datagrid-services, 

- 1 for use within the cluster, 
- 1 for ping service which ensures that the clusters are healthy and operational 
- and lastly the external service, which we will use to goto the Admin console.

Run the following command to get the `LoadBalancer` address 

[source, shell, role="copypaste"]
----
oc get services | grep datagrid-service-external | awk '{ print $4 }'
----

As you can see we have a service with our `LoadBalancer`. Let's get that url and paste it in the browser as follows

The following is an example, your `LoadBalancer` url will most likely differ:

* `http://ad6cd35d6e6aa46fcb96558204c35f08-872149037.us-east-1.elb.amazonaws.com:11222`


If you try to access the url; you would need to provide credentials. 

The datagrid operator creates the credentials during installation time and they should be stored in your namespace secrets. Let's get the secret with the following command.

[source, shell, role="copypaste"]
----
oc get secret datagrid-service-generated-secret -o jsonpath="{.data.identities\.yaml}" | base64 --decode
----

And now the final test to check we have a running cluster; login with the username developer and the password from the above secret.

image::dg_adminconsole.png[openshift_login, 900]


=== Recap
<1> You created your own CR
<2> Deployed the CR to Openshift using the DataGrid operator
<3> You installed your DataGrid instance

*Congratulations!!* you have completed the first Datagrid installation of this workshop. Let's move to the next lab and learn how we can use this instance as a RemoteCache with a Quarkus Application.
