= DatGrid 8 in 10 minutes
:experimental:

The latest update to Red Hat Runtimes is with the release of Red Hat Data Grid 8, which provides a distributed in-memory, NoSQL datastore solution. Your applications can access, process, and analyze data at in-memory speed to deliver a superior user experience. Whether using legacy applications or a new breed of microservices and functions, Red Hat Data Grid 8 will enable the journey to Open Hybrid Cloud. Data Grid includes the Infinispan open-source software project. It is available to deploy as an embedded library, a standalone server, or a containerized application on the Red Hat OpenShift Container Platform.

image::dg8.png[Red Hat Data Grid 8.2, 700]


=== A Full Lifecycle Operator to reduce deployment and management overhead in OpenShift
An Operator enables operations and lifecycle management for an application using the underlying Kubernetes API. That means complex applications (e.g. consumed as services such as distributed caching, databases, etc.) can easily get upgraded when newer versions arrive and more; also meaning no human intervention. The Operator SDK enables developers to write such Operators. Red Hat Data Grid 8 introduces a fully supported Data Grid Operator that provides operational intelligence.

=== A new server architecture 
Cloud and Container Native Data Grid needs a reduced footprint, and that's what the latest version of Red Hat Data Grid brings. It reduces both the disk footprint and initial heap size up to 50%, leaving more memory for your data. You can now run the server without the Red Hat JBoss Enterprise Application Platform (EAP), ensuring a lower memory and disk footprint also simplifying configuration. 

Moreover, Data Grid 8 servers provide several enhancements and improvements to security, including integration with Red Hat SSO and a smaller attack surface.

=== A more performant and rich REST API 
Red Hat Data Grid 8 introduces REST API v2. 
The API has 50% faster response rates compared to v1. There are also new capabilities introduced, such as:

* Access data and manipulate objects (such as counters)
* Perform operations such as gracefully shutting down Data Grid clusters or transferring cache state to backup locations when using cross-site replication
* And lastly, monitor cluster and server health and retrieve statistics

Moreover, Red Hat Data Grid REST API v2 automatically converts between storage formats such as JSON, XML, Protobuf, and plain text for increased interoperability. The Red Hat Data Grid engineering team develops and maintains comprehensive REST API Documentation.

=== A powerful CLI 
In 8, Data Grid gives you a new CLI with intuitive commands for remotely accessing data and managing clusters.
The CLI uses familiar Bash commands for navigating, such as `cd` and `ls`. It also provides command history and auto-completion for ease of use. 

Additionally, the CLI provides help text and man pages for commands with clear examples.

=== Enhanced observability 
Now you can use the `/metrics` endpoint for integration with Prometheus. Moreover, Red Hat Data Grid 8 is compatible with Eclipse Microprofile Metrics API. It also includes more specific metrics and gauges. Data Grid 8 also offers improved statistics and management operations via JMX and updates to logging with coarse-grained logging categories and support for logs in JSON format.

== What is Caching and how to apply it with Red Hat Data Grid?
Modern applications use data, let's assume lots of data, whether it comes from databases, files, web services, rpc call etc. 
When an application has to process it, what is the most natural way of doing it? Mostly, the application will process this data in memory. 
Let's assume I have a very slow database for any reason: Network latency or big queries that return a lot of data. 
The most straightforward way of handling this would be to store some of that data in memory. By doing so, you would be able to process requests to your systems much faster. However, there are challenges. How much data should you store in memory? And most importantly, what will happen in case of failure scenarios? 

* Will you lose all the state of your data in memory? 
* Will you need to re-read all your data and events to get back to the same state where you failed? Or you might have to let go of that entirely. 

The above two might seem very simple, but those tasks can be tedious and, most importantly, error prone. 
At this point, we could introduce a local cache (e.g. a `HashMap`) that most of us might have use in the past. However, as a developer, you might know that this doesn't have much effect in case of failures. 
So you need a component that can not just cache data in the memory but also give:

1. A consistent way to handle data and state in the memory.
2. Resiliency in case of failures.
3. Processing efficiency and performance.
4. Events, streams, and distribution capabilities.


image::caching.png[Caching, 700]


With such capabilities, the cache is no longer just an in-memory data structure. Therefore, as a developer, you can take this component out of your local in-memory processing and distribute it over the network. In case of application failures, you will still be able to access this data from the last point you left off. 

Now getting back to our primary question, how much data should you store in memory? Partially we have already discussed this above. It is important that, as a developer, you should be able to specify TTL (Time To Live) for your cache and its entries. 

You should also be able to define eviction and expiration. Eviction is used to prevent memory overuse and not to remove the entry from the cache, as it will drop an entry from memory on this instance, but it does not affect other instances or the persistence. It must be used with a configured persistence to be consistent. Whereas expiration will retire the entry and remove it from the cache and its persistence completely. Thereby knowing when your cache is hot and what data resides in it. Moreover you should be able to do this distributed, cluster-wide, or remotely. 

Once a cache is remote, we also want some of the distributed features, like monitoring for example. Lets take a look at some of the caching strategies.

==== Local cache
The primary use for Red Hat Data Grid is to provide a fast in-memory cache of frequently accessed data. Suppose you have a slow data source (database, web service, text file, etc.) - you could load some or all of that data in memory so that itâ€™s just a memory access away from your code. Using Red Hat Data Grid is better than using a simple `ConcurrentHashMap`. By setting up an embedded cache, Red Hat Dat Grid also allows you to tap into more features e.g. expiration, eviction, events on the cache etc. All make out a much better way of handling your cache and component design. Moreover, if you want to cluster such a cache that is also easily possible. 

==== As a clustered cache
Let's assume you started with a local/embedded cache in your application, but now you suddenly realize that one instance of your application is not enough to handle the load from your users or systems. What do you do? With Red Hat Data Grid you can now scale that cache into a cluster. 

You don't need to change how you use your cache. Adding a few additional parameters, you can now have a clustered cache having multiple instances of your application listening to the same coherent cache. 

Events will be fired across the cluster, expiration will happen across the cluster, etc. Eviction removes entries from the local instance memory if not used, but not from persistent cache stores or other cluster members to ensure that the local Data Grid does not exceed that maximum size. Moreover, you now even have the possibility to distribute your keys across the cluster. Red Hat Data Grid can scale horizontally to hundreds of nodes. 

==== As a remote cache
Let's just say you used the clustered cache, and embedded it in your application, so every time a new instance of your application is started you would have a new instance of your embedded cache ready to become part of the cluster. 

This sounds great! Although, what if you don't want that clustering in your application? Then, you might want to use a component from outside your application's lifecycle. Or you want to share this cache across multiple applications. In that case, the Red Hat Data Grid could act as a remote data grid. 

Now you can access your cache via multiple programming runtimes (e.g. Vert.x, Quarkus, NodeJS, C#, C/C++, etc.), and your cache lifecycle and memory consumption will be independent of the application's life cycle. Great advantage!

Congratulations! By now, you understand the different patterns of caching and the requirements. Let's go ahead and create our first application and learn how to use Red Hat Data Grid to achieve caching. Press next! 

 
=== Additional Resources:
- Traditional zip deployments are available on the link:https://access.redhat.com[Customer Portal, window=_blank] link:https://access.redhat.com/jbossnetwork/restricted/listSoftware.html?downloadType=distributions&product=data.grid[Red Hat Data Grid download page, window=_blank].
- The container distribution and operator are available in the link:https://catalog.redhat.com/software/containers/explore[Red Hat Container Catalog, window=_blank]
- Product documentation is available link:https://docs.redhat.com[here, window=_blank]
- Getting Started Guide that will get you running with RHDG 8 in 5 minutes.
- link:https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.2/html/migrating_to_data_grid_8/index[Migration Guide, window=_blank] 
- link:https://github.com/redhat-developer/redhat-datagrid-tutorials[Starter Tutorials, window=_blank]
- link:https://access.redhat.com/articles/4933371[Supported Components, window=_blank]
- link:https://access.redhat.com/articles/4933551[Supported Configurations, window=_blank]

