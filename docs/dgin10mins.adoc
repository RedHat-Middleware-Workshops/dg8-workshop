= DatGrid 8.x in 10 minutes
:experimental:

The latest update to Red Hat Runtimes is with the release of Red Hat Data Grid 8.2, which provides a distributed in-memory, NoSQL datastore solution. Your applications can access, process, and analyze data at in-memory speed to deliver a superior user experience. Whether you are using legacy applications or a new breed of microservices and functions, Red Hat Data Grid 8.2 will enable the journey to Open Hybrid Cloud. Data Grid includes the Infinispan open-source software project. It is available to deploy as an embedded library, as a standalone server, or as a containerized application on Red Hat OpenShift Container Platform. 

image::dg8.png[Red Hat Data Grid 8.2, 700]


=== A Full Lifecycle Operator to reduce deployment and management overhead in OpenShift
An Operator enables the operations and lifecycle management for an application by using the underlying Kubernetes APIs. That means complex applications (e.g. consumed as services such as distributed caching, databases, etc) can easily get upgraded when newer versions arrive and more; also meaning no human intervention. The Operator SDK enables developers to write such Operators. Red Hat Data Grid 8 introduces a fully supported Data Grid Operator that provides operational intelligence.

=== A new server architecture 
Cloud and Container Native Data Grid needs to have a reduced footprint, and that's what the latest version of Red Hat Data Grid brings. It reduces both the disk footprint and initial heap size up to 50%, leaving more memory for your data. You can now run the server without the Red Hat JBoss Enterprise Application Platform (EAP), ensuring a lower memory and disk footprint
also simplifying configuration. 

Moreover, Data Grid 8 servers provide several enhancements and improvements to security, including integration with Red Hat SSO and a smaller attack surface.

=== A more performant and rich REST API 
Red Hat Data Grid 8 introduces REST API v2. 
The API has 50% faster response rates compared to v1. There are also new capabilities introduced such as

* Access data and manipulate objects (such as counters)
* Perform operations such as gracefully shutting down Data Grid clusters or transferring cache state to backup locations when using cross-site replication
* And lastly, monitor cluster and server health and retrieve statistics

Moreover, Red Hat Data Grid REST API v2 also automatically converts between storage formats such as JSON, XML, Protobuf, and plain text for increased interoperability. The Red Hat Data Grid engineering team develops and maintains comprehensive REST API Documentation.

=== A powerful CLI 
In 8, Data Grid gives you a new CLI with intuitive commands for remotely accessing data and managing clusters.
The CLI uses familiar Bash commands for navigating, such as `cd` and `ls`. It also provides command history and auto-completion for ease of use. 

Additionally, the CLI provides help text and man pages for commands with clear examples.

=== Enhanced observability 
Now you can use the `/metrics` endpoint for integration with Prometheus. Moreover, Red Hat Data Grid 8 is also compatible with Eclipse Microprofile Metrics API. More specific metrics and gauges are included. Data Grid 8 also offers improved statistics and management operations via JMX and updates to logging with coarse-grained logging categories and support for logs in JSON format.

== What is Caching and how to apply it with Red Hat Data Grid?
Modern applications use data and lets assume lots of data, whether it comes from databases, files, web services, rpc call etc. 
When an application has to process this data, what is the most natural way of doing it? Mostly the application will process this data in memory. 
Let's assume I have a very slow database, this could be due to any reason, network latency, or even big queries that return a lot of data. 
So the most straightforward way of handling this would be to store some of that data in the memory. By doing so, you would be able to process requests to your systems much faster. However there are challenges. How much data should you store in memory? And most importantly, what will happen in case of failure scenarios? 

* Will you lose all the state of your data in memory? 
* Will you need to re-read all your data and events in order to get back to the same state where you failed. Or you might have to let go of that entirely. 

Now the above two might seem very simple, but that tasks can be tedious and most importantly error prone. 
So at this point we could introduce a local cache (e.g. a `HashMap`) that a lot of us might have done this in the past. However as a developer you might know that this has not much effect in case of failures. 
So the need is entirely for a component that can not just cache data in the memory, but give 

1. A consistent way to handle data and state in the memory.
2. Resiliency in case of failures.
3. Processing efficiency and performance.
4. Events, streams, and distribution capabilities.


image::caching.png[Caching, 700]


By having such capabilities a cache is no longer just an in-memory data structure, but also as a developer now you have the possibility to take this component out of your local in memory processing and distribute it out on the network. Thereby in case of application failures you will still be able to access this data from the last point where you left off. 

Now getting back to our primary question, how much data should you store in memory? Partially we have already discussed this above. Whats important is that as a developer you should be able to specify TTL (Time To Live) for your cache and its entries. You should be able to define eviction and expiration. Note that eviction is to prevent from memory overuse and not to remove the entry from the cache, it will drop an entry from memory on this instance and does not affect other instances or the persistence. It must be used with a configured persistence to be consistent.
Whereas expiration will retire the entry and remove it from the cache and its persistence completely.
There by knowing when your cache is hot and what data resides in it. Most over you should be able to do this distributed, cluster wide, or remotely. 

Once a cache is remote, we also want some of the distributed features, like monitoring for example. Lets take a look at some of the caching strategies.

==== Local cache
The primary use for Red Hat Data Grid is to provide a fast in-memory cache of frequently accessed data. Suppose you have a slow data source (database, web service, text file, etc) - you could load some or all of that data in memory so that itâ€™s just a memory access away from your code. Using Red Hat Data Grid is better than using a simple `ConcurrentHashMap`. By setting up an embedded cache, Red Hat Dat Grid also allows you to tap into more features e.g. expiration, eviction, events on the cache etc. All make out a much better way of handling your cache and component design. Moreover if you would want to cluster such a cache that is also easily possible. 

==== As a clustered cache
Lets assume you started with a local embedded cache in your application and now you suddenly realize that one instance of your application is not enough to handle the load from your users or systems. What do you do? With Red Hat Data Grid you can now scale that cache into a cluster. You don't need to change how you use your cache, but adding a few additional config params you can now have a clustered cache and by having multiple instances of your application listening to the same coherent cache. Events will be fired across the cluster, expiration will happen across the cluster, etc. Eviction removes entries from the local instance memory if not used, but not from persistent cache stores or other cluster members to ensure that the local Data Grid does not exceed that maximum size. And most over, you now even have the possibility to distribute your keys across the cluster. Red Hat Data Grid can scale horizontally to hundreds of nodes. 

==== As a remote cache
Lets just say you used the clustered cache, and embedded it in your application, which means that every time a new instance of your application started you would have a new instance of your embedded cache ready to become part of the cluster. Now this is all great, but what if you don't want that clustering in your application? Rather then you might want to use a component outside of your applications lifecycle. Or you would want to share this cache across multiple applications. In that case the Red Hat Data Grid could be used as a remote data grid. Now you can access your cache via multiple programming runtimes (e.g. Vert.x, Quarkus, NodeJS, C#, C/C++ etc), and your cache lifecycle and memory consumption will be independent of the applications life cycle, which is a great advantage in many cases.

Congratulations! By now you understand the different patterns of caching, and the requirements. Lets go ahead and create our first application and learn how we can use Red Hat Data Grid to achieve caching. Press next! 

 
=== Additional Resources:
- Traditional zip deployments are available on the link:https://access.redhat.com[Customer Portal, window=_blank] link:https://access.redhat.com/jbossnetwork/restricted/listSoftware.html?downloadType=distributions&product=data.grid[Red Hat Data Grid download page, window=_blank].
- The container distribution and operator are available in the link:https://catalog.redhat.com/software/containers/explore[Red Hat Container Catalog, window=_blank]
- Product documentation is available link:https://docs.redhat.com[here, window=_blank]
- Getting Started Guide that will get you running with RHDG 8 in 5 minutes.
- link:https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.2/html/migrating_to_data_grid_8/index[Migration Guide, window=_blank] 
- link:https://github.com/redhat-developer/redhat-datagrid-tutorials[Starter Tutorials, window=_blank]
- link:https://access.redhat.com/articles/4933371[Supported Components, window=_blank]
- link:https://access.redhat.com/articles/4933551[Supported Configurations, window=_blank]

